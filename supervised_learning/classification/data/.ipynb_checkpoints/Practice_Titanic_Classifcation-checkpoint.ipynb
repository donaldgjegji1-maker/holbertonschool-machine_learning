{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1de052d3-ac5f-4203-8dbf-73ac535fb88b",
   "metadata": {},
   "source": [
    "# Titanic: The Logic of Survival\n",
    "\n",
    "![Titanic](https://i.imgur.com/3CsSroz.jpeg)\n",
    "\n",
    "## A \"White Box\" Detective Story\n",
    "\n",
    "In our previous analysis of the `Titanic` dataset, we played the role of a **Data Detective**. We looked at charts, calculated averages, and found patterns like `\"Women and children first.\"`\n",
    "\n",
    "But knowing *what* happened is different from predicting *what will* happen.\n",
    "\n",
    "Today, we are upgrading from **Detectives** to **Engineers**. We will build a machine that can look at a passenger's ticket and predict their fate.\n",
    "\n",
    "### The Goal: End-to-End Machine Learning\n",
    "This is your first complete Machine Learning project. We will follow the standard 4-step workflow used by data scientists at Google, Netflix, and Amazon:\n",
    "\n",
    "1.  **Data Preparation:** Formatting the data so the computer can read it (Computers speak numbers, not English).\n",
    "2.  **The Split:** separating data into \"Study Material\" and \"Exam Material.\"\n",
    "3.  **The Model:** Training a **Decision Tree**; a model that learns by creating a flowchart of rules.\n",
    "4.  **Evaluation:** Grading our model to see if it's actually smart or just guessing.\n",
    "\n",
    "###  Phase 0. The Setup\n",
    "First, we need to load our tools. We will use `pandas` for data handling and `sklearn` (Scikit-Learn) for building the brain of our operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "488d8794-903b-4d83-b2fc-9fee058b900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We will also import the specific tools we need for the model later\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Configuration to make charts look nice\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ad92ec-446a-466f-bb7f-f82e768b73e7",
   "metadata": {},
   "source": [
    "#### Inspection (The Health Check)\n",
    "Before we can train a model, we must interrogate our data. We need to know three things:\n",
    "1.  **Shape:** How much data do we have?\n",
    "2.  **Content:** What does the data look like?\n",
    "3.  **Health:** Are there missing values (holes) in the evidence?\n",
    "\n",
    "We will use the Seaborn Titanic dataset. Note that this version contains some redundant columns (like `who` and `alive`) which are duplicates of `sex` and `survived`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1803783-53f6-4c58-9ed5-bd3a91b2710b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (891, 15)\n",
      "------------------------------\n",
      "\n",
      "Missing Values:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load the dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# 2. Quick \"Health Check\"\n",
    "print(f\"Data Shape: {df.shape}\")\n",
    "print(\"-\" * 30)\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 3. Peek at the raw data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551f409b-419c-4c8d-b943-91d65e69e4f2",
   "metadata": {},
   "source": [
    "### Phase 1. Data Preparation\n",
    "\n",
    "#### The Cleanup (Triage)\n",
    "A Machine Learning model is like a calculator; it will crash if you try to feed it \"Not a Number\" (NaN). Looking at our health check above, we have a few problems:\n",
    "\n",
    "1.  **`deck`**: Has too many missing values (over 70%). It's too damaged to save. **Decision: Drop it.**\n",
    "2.  **`age`**: Missing about 177 values. Age is a critical factor for survival. **Decision: Fill missing values with the median age.**\n",
    "3.  **`embarked`**: Only 2 missing. **Decision: Drop those 2 rows.**\n",
    "4.  **Redundant Columns**: `embark_town`, `class`, `who`, `adult_male`, `alive` are duplicates provided by Seaborn. **Decision: Drop them to keep it clean.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8698d6d-60a9-4e62-9b53-3ac72e1c1de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Drop the \"Unsalvageable\" and \"Redundant\" columns\n",
    "\n",
    "# 2. Drop the 2 rows with missing 'embarked' data\n",
    "\n",
    "# 3. Fill missing 'age' with the median (Safe bet)\n",
    "\n",
    "# Verify the cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d6af63-efb0-45fe-b754-b015c37243cc",
   "metadata": {},
   "source": [
    "#### Feature Engineering (Translation)\n",
    "Computers speak math, not English. We cannot feed the model words like \"male\" or \"female.\" We must translate these into numbers.\n",
    "\n",
    "*   **Sex:** `male -> 0`, `female -> 1`\n",
    "*   **Embarked:** `S -> 0`, `C -> 1`, `Q -> 2`\n",
    "\n",
    "We will also select exactly which features (evidence) we want to show the jury (the Model).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feb88cc7-9c02-45e7-93a3-0fedf651a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Translate \"Sex\" to numbers\n",
    "\n",
    "# 2. Translate \"Embarked\" to numbers\n",
    "\n",
    "# 3. Define our Features (X) and Target (y)\n",
    "# X = The questions we ask (Ticket Class, Sex, Age, Fare, etc.)\n",
    "# y = The answer (Did they survive?)\n",
    "\n",
    "# Final check: X should be all numbers now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff270ef-a848-48bb-93ac-17fe3fa32c68",
   "metadata": {},
   "source": [
    "### Phase 2: The Split (Study Material vs. Exam)\r\n",
    "This is the most important concept in Machine Learning.\r\n",
    "\r\n",
    "If we teach the model using **all** the data, and then ask it to predict that **same** data, we are cheating. It's like giving a student the answer key to study, and then giving them the exact same questions on the final exam. They will score 100%, but they haven't learned anything; they just memorized the answers.\r\n",
    "\r\n",
    "To test if our model is actually *smart*, we must hide some data from it.\r\n",
    "*   **Training Set (80%):** The \"Study Guide.\" The model sees this to learn the rules.\r\n",
    "*   **Test Set (20%):** The \"Final Exam.\" The model never sees this until the very end.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1085bd07-02a3-473f-a113-a2ccdf1b2763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split the data\n",
    "# test_size=0.2 means 20% is saved for the \"Exam\", 80% for \"Studying\"\n",
    "# random_state=42 ensures we get the same split every time (reproducibility)\n",
    "\n",
    "# 2. Check the sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0549a84c-1a25-42ae-894e-9aef06644d9a",
   "metadata": {},
   "source": [
    "### Phase 3: Training the Model\n",
    "Now we build the brain. We are using a **Decision Tree**.\n",
    "\n",
    "Imagine a flow chart. The model looks at a passenger and asks:\n",
    "1.  *\"Is this a man?\"* (Yes/No)\n",
    "2.  *\"Is he rich (First Class)?\"* (Yes/No)\n",
    "3.  *\"Is he a child?\"* (Yes/No)\n",
    "\n",
    "**Crucial Step:** We will set `max_depth=3`.\n",
    "If we don't limit the depth, the tree will grow wildly complex, creating a specific rule for every single passenger (memorization). Limiting the depth forces it to find the simple, broad rules that apply to everyone (generalization).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "334d08bd-5761-431d-b2f4-37d88dee45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initialize the \"Brain\"\n",
    "# max_depth=3 keeps the tree simple enough to visualize and understand\n",
    "\n",
    "# 2. Teach the model (Fit)\n",
    "# This is where the magic happens. The model looks at X_train and y_train to find patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c6c0e4-9cae-4540-8415-41cf946a8c93",
   "metadata": {},
   "source": [
    "### Phase 4: Visualizing the \"Mind\" of the Model\n",
    "This is the best part of using Decision Trees: they are \"White Box\" models. Unlike Neural Networks, which are mysterious black boxes, we can see exactly how this model thinks.\n",
    "\n",
    "We will draw the tree it just learned.\n",
    "*   **Blue boxes:** High probability of survival.\n",
    "*   **Orange boxes:** High probability of death.\n",
    "*   **White boxes:** Uncertain (mixed group).\n",
    "\n",
    "Read the tree from top to bottom. The very first question at the top is the most important rule the model discovered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6b21e79-96fc-4c77-8a2b-7f6c9ed82095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f7e067-47b6-4897-8652-3baffdf632af",
   "metadata": {},
   "source": [
    "### Phase 5: The Final Exam (Evaluation)\n",
    "The tree looks smart, but does it work?\n",
    "We now give it the **Test Set**: the 20% of passengers we hid earlier. The model will make a prediction for each one, and we will calculate the **Accuracy Score**.\n",
    "\n",
    "*   **Accuracy:** The percentage of correct predictions (e.g., 0.80 means 80% correct).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13f59274-875a-476b-8e3d-27b4852df24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make predictions on the Test Set\n",
    "\n",
    "# 2. Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e494491-b56f-421d-9b1a-a9115e07c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a few specific examples from the exam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0047364e-cb90-4137-a313-9792561ae0f1",
   "metadata": {},
   "source": [
    "### Phase 6: The Ultimate Test (Could Jack Survive?)\r\n",
    "We started this story by asking if we could predict survival. Now, let's test our model on the most famous passenger of all: **Jack Dawson**.\r\n",
    "\r\n",
    "We need to create a profile for him based on what we know from the movie:\r\n",
    "*   **Class:** 3rd Class (`pclass = 3`)\r\n",
    "*   **Sex:** Male (`sex = 0` based on our map)\r\n",
    "*   **Age:** 20 (`age = 20`)\r\n",
    "*   **Siblings/Spouses:** 0 (`sibsp = 0`)\r\n",
    "*   **Parents/Children:** 0 (`parch = 0`)\r\n",
    "*   **Fare:** Cheap (`fare = 7.50`)\r\n",
    "*   **Embarked:** Southampton (`embarked = 0`)\r\n",
    "\r\n",
    "Let's ask our model the big question.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eaf4f636-9b8b-43e3-8592-c472b7570048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create Jack's Data Profile\n",
    "# We must use the exact same column order as our 'features' list\n",
    "# features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
    "\n",
    "\n",
    "# 2. Ask the Model\n",
    "\n",
    "# 3. Reveal the Fate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3154a05-b800-4c1a-bb3e-055d859dfac4",
   "metadata": {},
   "source": [
    "## Summary of Our Investigation\n",
    "\n",
    "Congratulations! You have successfully built your first End-to-End Machine Learning model. Let's review what we achieved today:\n",
    "\n",
    "1.  **Data Translation:** We took messy, human data (\"male\", \"female\", \"missing ages\") and translated it into a clean matrix of numbers that a computer can understand.\n",
    "2.  **The Split:** We protected our model from \"cheating\" by hiding 20% of the data for the final exam.\n",
    "3.  **The Logic:** We visualized exactly *how* the model makes decisions. We saw that **Sex**, **Class**, and **Age** were the deciding factorsâ€”confirming our \"Women and Children First\" hypothesis from the EDA phase.\n",
    "4.  **The Result:** We achieved an accuracy score (likely between 78-82%), meaning our simple set of rules can correctly predict the fate of 4 out of 5 passengers.\n",
    "\n",
    "### \"White Box\" vs. \"Black Box\"\n",
    "Today we used a **Decision Tree**, which is a \"White Box\" model. You can see every rule it made.\n",
    "In future lessons, we will use models like **Neural Networks**. They are \"Black Boxes\"; they might be more accurate, but they won't tell you *why* they made a decision.\n",
    "\n",
    "### Your Challenge: Can You Beat the Score?\n",
    "Don't stop here. Your goal is to push the accuracy higher (can you hit 85%?) without changing the model type. Try these three experiments:\n",
    "\n",
    "1.  **Select Better Features:**\n",
    "    We used `['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']`.\n",
    "    *   Does the model get confused by too much information? Try removing `fare` or `embarked`.\n",
    "    *   Does it need *more* info? Try finding a way to use the `deck` information (if you can fix the missing values).\n",
    "\n",
    "2.  **Feature Engineering (Create New Data):**\n",
    "    Sometimes the raw data isn't enough. You can create your own columns!\n",
    "    *   **Family Size:** Create a new column called `family_size` by adding `sibsp` + `parch`. Does having a large family hurt your chances?\n",
    "    *   **Age Groups:** Instead of exact age (22, 35, 50), try grouping them into buckets: \"Child\" (0-12), \"Adult\" (13-60), \"Senior\" (60+).\n",
    "\n",
    "3.  **Tune the \"Brain\" (Hyperparameters):**\n",
    "    We set `max_depth=3` to keep the tree simple.\n",
    "    *   What happens if you increase it to `max_depth=5` or `10`?\n",
    "    *   **Warning:** If you make the tree too deep, it might memorize the training data (100% score) but fail the exam (low test score). This is called **Overfitting**. Can you find the \"sweet spot\"?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb2fcce-06da-44c9-866f-f62af3a6fb97",
   "metadata": {},
   "source": [
    "\n",
    "> *\"I figure life's a gift and I don't intend on wasting it. You don't know what hand you're gonna get dealt next. You learn to take life as it comes at you... to make each day count.\"*\n",
    "> **Jack Dawson**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
